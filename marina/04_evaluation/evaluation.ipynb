{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of implemented approaches üèÖ\n",
    "This notebook is dedicated to the evaluation of the approaches we have implemented for validation assessment. <br>\n",
    "The ornithologists have provided us with a dataset containing both correct and falsified data. The falsified data was generated by duplicating correct data and making slight modifications to render them invalid, such as altering the date or bird species information.\n",
    "\n",
    "This dataset lacks information regarding the validity of the datapoints (i.e. if the datapoint is correct or was falsified by the ornithologists). Therefore, in this notebook, we create a column named 'IS_INVALID_PREDICTION' which indicates whether our model predicts the data to be invalid or not. The ornithologists subsequently compare this column with the ground truth and provide us with feedback.\n",
    "\n",
    "***\n",
    "\n",
    "You can download the validation data [here](https://drive.google.com/drive/folders/1emvbXc5ExoEgv7Pmwy_Y5rjNc9k8hrNs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from utils.data_preparation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data we want to predict on\n",
    "path_validata = '../../../01_Data/datasets/validata_ornitho_ch_2023.csv'\n",
    "date_format = '%d.%m.%Y'  # ch: '%d.%m.%Y'; de: %m/%d/%Y\n",
    "\n",
    "# Data we need for data preparation\n",
    "path_translator_names = '../../../01_Data/translators/translation_species_names_de_vs_ch.csv'\n",
    "path_eea_grids = '../../../01_Data/eea_gridfiles/eea_europe_grids_50km/inspire_compatible_grid_50km.shp'\n",
    "\n",
    "# Where to store the results\n",
    "target_path = '../../../01_Data/results/results_emergent_filters_ch_5%.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "validata = pd.read_csv(path_validata, delimiter=get_delimiter(path_validata), low_memory=False)\n",
    "validata = standardize_data(validata, \n",
    "                            date_format=date_format,\n",
    "                            path_translator_species_names=path_translator_names, \n",
    "                            eea_shapefile_path=path_eea_grids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£  Emergent Filters\n",
    "In order to conduct the evaluation using Emergent Filters, it is necessary to obtain the Emergent Filters themselves. These can be generated using the notebook 02_Emergent_Filters.ipynb. The Emergent Filters for the dataset *selected_bird_species_with_grids_50km.csv* can be downloaded from here in the form of a file named *emergent_filters_selected_species_grids_50km.pkl*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_path = '/Users/marinasiebold/Library/Mobile Documents/com~apple~CloudDocs/Studium/Bird_Research/01_Data/models/emergent_filters_selected_species_grids_50km.pkl'  # path to emergent filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filters_path, 'rb') as file:\n",
    "    emergent_filters = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "validata['day_of_year'] = pd.to_datetime(validata.date).dt.dayofyear\n",
    "validata = validata[['name_species', 'eea_grid_id', 'day_of_year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the emergent filters for assessing the validation data provided by ornitho, we use the `is_unlikely`-function from *02_Emergent_Filter.ipynb*. <br>\n",
    "For each datapoint in the validation dataframe, this function simply extracts the plausibility value from the emergent filters that correspond to the given species, grid, and date. If this value falls below the predetermined threshold, the `flagged_for_review` flag is set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_unlikely(sighting, emergent_filters_lookup, threshold=0.05):\n",
    "    key = (sighting.name_species, sighting.eea_grid_id, sighting.day_of_year)\n",
    "    plausibility = emergent_filters_lookup.get(key, None)\n",
    "    return plausibility is not None and plausibility < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_species</th>\n",
       "      <th>eea_grid_id</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>flagged_for_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alpenschneehuhn</td>\n",
       "      <td>50kmE4300N2650</td>\n",
       "      <td>166</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bergente</td>\n",
       "      <td>50kmE4250N2700</td>\n",
       "      <td>97</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bergente</td>\n",
       "      <td>50kmE4250N2700</td>\n",
       "      <td>87</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gelbsp√∂tter</td>\n",
       "      <td>50kmE4300N2700</td>\n",
       "      <td>133</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Haubentaucher</td>\n",
       "      <td>50kmE4250N2700</td>\n",
       "      <td>49</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87054</th>\n",
       "      <td>Haubentaucher</td>\n",
       "      <td>50kmE4150N2550</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87055</th>\n",
       "      <td>Schwarzkehlchen</td>\n",
       "      <td>50kmE4100N2550</td>\n",
       "      <td>71</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87056</th>\n",
       "      <td>Braunkehlchen</td>\n",
       "      <td>50kmE4150N2500</td>\n",
       "      <td>138</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87057</th>\n",
       "      <td>Kn√§kente</td>\n",
       "      <td>50kmE4150N2500</td>\n",
       "      <td>76</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87058</th>\n",
       "      <td>G√§nsegeier</td>\n",
       "      <td>50kmE4150N2500</td>\n",
       "      <td>179</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87059 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name_species     eea_grid_id  day_of_year  flagged_for_review\n",
       "0      Alpenschneehuhn  50kmE4300N2650          166               False\n",
       "1             Bergente  50kmE4250N2700           97                True\n",
       "2             Bergente  50kmE4250N2700           87                True\n",
       "3          Gelbsp√∂tter  50kmE4300N2700          133               False\n",
       "4        Haubentaucher  50kmE4250N2700           49               False\n",
       "...                ...             ...          ...                 ...\n",
       "87054    Haubentaucher  50kmE4150N2550            3                True\n",
       "87055  Schwarzkehlchen  50kmE4100N2550           71               False\n",
       "87056    Braunkehlchen  50kmE4150N2500          138                True\n",
       "87057         Kn√§kente  50kmE4150N2500           76                True\n",
       "87058       G√§nsegeier  50kmE4150N2500          179                True\n",
       "\n",
       "[87059 rows x 4 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validata['flagged_for_review'] = validata.apply(is_unlikely, args=(emergent_filters,threshold,), axis=1)\n",
    "validata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flagged_for_review\n",
       "False    82709\n",
       "True      4350\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validata.flagged_for_review.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append review flags to original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(path_validata, delimiter=get_delimiter(path_validata), low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data['ERROR_DETECTED'] = validata.flagged_for_review\n",
    "original_data.to_csv(target_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bird",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
