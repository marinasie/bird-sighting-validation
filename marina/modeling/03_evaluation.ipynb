{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of implemented approaches üèÖ\n",
    "This notebook is dedicated to the evaluation of the approaches we have implemented for validation assessment. <br>\n",
    "The ornithologists have provided us with a dataset containing both correct and falsified data. The falsified data was generated by duplicating correct data and making slight modifications to render them invalid, such as altering the date or bird species information.\n",
    "\n",
    "This dataset lacks information regarding the validity of the datapoints (i.e. if the datapoint is correct or was falsified by the ornithologists). Therefore, in this notebook, we create a column named 'IS_INVALID_PREDICTION' which indicates whether our model predicts the data to be invalid or not. The ornithologists subsequently compare this column with the ground truth and provide us with feedback.\n",
    "\n",
    "***\n",
    "\n",
    "You can download the validation data [here](https://drive.google.com/drive/folders/1emvbXc5ExoEgv7Pmwy_Y5rjNc9k8hrNs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from utils.data_preparation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data we want to predict on\n",
    "path_validata = '../../../01_Data/datasets/validata_ornitho_ch_2023.csv'\n",
    "date_format = '%d.%m.%Y'  # ch: '%d.%m.%Y'; de: %m/%d/%Y\n",
    "\n",
    "# Data we need for data preparation\n",
    "path_translator_names = '../../../01_Data/translators/translation_species_names_de_vs_ch.csv'\n",
    "path_eea_grids = '../../../01_Data/eea_gridfiles/eea_europe_grids_50km/inspire_compatible_grid_50km.shp'\n",
    "\n",
    "# Where to store the results\n",
    "target_path = '../../../01_Data/results/results_emergent_filters_ch_1%.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validata = pd.read_csv(path_validata, delimiter=get_delimiter(path_validata), low_memory=False)\n",
    "validata = standardize_data(validata, \n",
    "                            date_format=date_format,\n",
    "                            path_translator_species_names=path_translator_names, \n",
    "                            eea_shapefile_path=path_eea_grids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£  Emergent Filters\n",
    "In order to conduct the evaluation using Emergent Filters, it is necessary to obtain the Emergent Filters themselves. These can be generated using the notebook 02_Emergent_Filters.ipynb. The Emergent Filters for the dataset *selected_bird_species_with_grids_50km.csv* can be downloaded from here in the form of a file named *emergent_filters_selected_species_grids_50km.pkl*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_path = '/Users/marinasiebold/Library/Mobile Documents/com~apple~CloudDocs/Studium/Bird_Research/01_Data/models/emergent_filters_selected_species_grids_50km.pkl'  # path to emergent filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filters_path, 'rb') as file:\n",
    "    emergent_filters = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "validata['day_of_year'] = pd.to_datetime(validata.date).dt.dayofyear\n",
    "validata = validata[['name_species', 'eea_grid_id', 'day_of_year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the emergent filters for assessing the validation data provided by ornitho, we use the `is_unlikely`-function from *02_Emergent_Filter.ipynb*. <br>\n",
    "For each datapoint in the validation dataframe, this function simply extracts the plausibility value from the emergent filters that correspond to the given species, grid, and date. If this value falls below the predetermined threshold, the `flagged_for_review` flag is set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_unlikely(sighting, emergent_filters_lookup, threshold=0.05):\n",
    "    key = (sighting.name_species, sighting.eea_grid_id, sighting.day_of_year)\n",
    "    plausibility = emergent_filters_lookup.get(key, None)\n",
    "    return plausibility is not None and plausibility < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_species</th>\n",
       "      <th>eea_grid_id</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>flagged_for_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alpenschneehuhn</td>\n",
       "      <td>50kmE4300N2700</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alpenschneehuhn</td>\n",
       "      <td>50kmE4300N2700</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alpenschneehuhn</td>\n",
       "      <td>50kmE4300N2700</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alpenschneehuhn</td>\n",
       "      <td>50kmE4300N2700</td>\n",
       "      <td>59</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alpenschneehuhn</td>\n",
       "      <td>50kmE4300N2650</td>\n",
       "      <td>126</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330823</th>\n",
       "      <td>Zwergohreule</td>\n",
       "      <td>50kmE4150N3400</td>\n",
       "      <td>146</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330824</th>\n",
       "      <td>Zwergohreule</td>\n",
       "      <td>50kmE4200N3450</td>\n",
       "      <td>161</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330825</th>\n",
       "      <td>Zwergohreule</td>\n",
       "      <td>50kmE4350N3450</td>\n",
       "      <td>135</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330826</th>\n",
       "      <td>Zwergohreule</td>\n",
       "      <td>50kmE4450N3450</td>\n",
       "      <td>106</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330827</th>\n",
       "      <td>Zwergohreule</td>\n",
       "      <td>50kmE4200N3500</td>\n",
       "      <td>151</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282581 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name_species     eea_grid_id  day_of_year  flagged_for_review\n",
       "0       Alpenschneehuhn  50kmE4300N2700           20                True\n",
       "1       Alpenschneehuhn  50kmE4300N2700           20                True\n",
       "2       Alpenschneehuhn  50kmE4300N2700           31               False\n",
       "3       Alpenschneehuhn  50kmE4300N2700           59               False\n",
       "6       Alpenschneehuhn  50kmE4300N2650          126               False\n",
       "...                 ...             ...          ...                 ...\n",
       "330823     Zwergohreule  50kmE4150N3400          146                True\n",
       "330824     Zwergohreule  50kmE4200N3450          161                True\n",
       "330825     Zwergohreule  50kmE4350N3450          135                True\n",
       "330826     Zwergohreule  50kmE4450N3450          106                True\n",
       "330827     Zwergohreule  50kmE4200N3500          151                True\n",
       "\n",
       "[282581 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validata['flagged_for_review'] = validata.apply(is_unlikely, args=(emergent_filters,threshold,), axis=1)\n",
    "validata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flagged_for_review\n",
       "False    278425\n",
       "True       4156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validata.flagged_for_review.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append review flags to original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(path_validata, delimiter=get_delimiter(path_validata), low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data['ERROR_DETECTED'] = validata.flagged_for_review\n",
    "original_data.to_csv(target_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bird",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
